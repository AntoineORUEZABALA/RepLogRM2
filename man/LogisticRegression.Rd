% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/LogisticRegression.R
\name{LogisticRegression}
\alias{LogisticRegression}
\title{Logistic Regression R6 Class}
\description{
This R6 class implements logistic regression for binary and multinomial classification.
It supports L1 and L2 regularization, as well as early stopping based on loss convergence.
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{weights}}{A matrix storing the model weights (including intercepts).}

\item{\code{learning_rate}}{A numeric value specifying the learning rate for gradient descent.}

\item{\code{max_iter}}{An integer specifying the maximum number of iterations for training.}

\item{\code{classification_type}}{A character string ("binary" or "softmax") specifying the classification type.}

\item{\code{regularization}}{A character string ("l1", "l2", or NULL) indicating the type of regularization.}

\item{\code{reg_lambda}}{A numeric value specifying the regularization strength.}

\item{\code{tolerance}}{A numeric value specifying the convergence tolerance for early stopping.}

\item{\code{losses}}{A numeric vector storing the loss values for each epoch during training.}

\item{\code{epoch}}{An integer specifying the current epoch during training.}

\item{\code{intercept}}{A numeric value storing the model's intercept.}

\item{\code{coefficients}}{A numeric vector storing the model's coefficients.}

\item{\code{X_test}}{A matrix or data frame representing the test features.}

\item{\code{y_test}}{A vector representing the test labels.}

\item{\code{X_train}}{A matrix or data frame representing the training features.}

\item{\code{y_train}}{A vector representing the training labels.}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-LogisticRegression-new}{\code{LogisticRegression$new()}}
\item \href{#method-LogisticRegression-print}{\code{LogisticRegression$print()}}
\item \href{#method-LogisticRegression-summary}{\code{LogisticRegression$summary()}}
\item \href{#method-LogisticRegression-sigmoid}{\code{LogisticRegression$sigmoid()}}
\item \href{#method-LogisticRegression-softmax}{\code{LogisticRegression$softmax()}}
\item \href{#method-LogisticRegression-forward}{\code{LogisticRegression$forward()}}
\item \href{#method-LogisticRegression-log_loss}{\code{LogisticRegression$log_loss()}}
\item \href{#method-LogisticRegression-cross_entropy_loss}{\code{LogisticRegression$cross_entropy_loss()}}
\item \href{#method-LogisticRegression-update_weights}{\code{LogisticRegression$update_weights()}}
\item \href{#method-LogisticRegression-initialize_weights}{\code{LogisticRegression$initialize_weights()}}
\item \href{#method-LogisticRegression-fit}{\code{LogisticRegression$fit()}}
\item \href{#method-LogisticRegression-predict}{\code{LogisticRegression$predict()}}
\item \href{#method-LogisticRegression-print_weights}{\code{LogisticRegression$print_weights()}}
\item \href{#method-LogisticRegression-predict_proba}{\code{LogisticRegression$predict_proba()}}
\item \href{#method-LogisticRegression-precision}{\code{LogisticRegression$precision()}}
\item \href{#method-LogisticRegression-recall}{\code{LogisticRegression$recall()}}
\item \href{#method-LogisticRegression-f1_score}{\code{LogisticRegression$f1_score()}}
\item \href{#method-LogisticRegression-confusion_matrix}{\code{LogisticRegression$confusion_matrix()}}
\item \href{#method-LogisticRegression-export_pmml}{\code{LogisticRegression$export_pmml()}}
\item \href{#method-LogisticRegression-clone}{\code{LogisticRegression$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LogisticRegression-new"></a>}}
\if{latex}{\out{\hypertarget{method-LogisticRegression-new}{}}}
\subsection{Method \code{new()}}{
This method initializes the logistic regression model with specified parameters.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LogisticRegression$new(
  learning_rate = 0.01,
  max_iter = 1000,
  classification_type = "binary",
  regularization = NULL,
  reg_lambda = 0.01,
  tolerance = 1e-04
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{learning_rate}}{A numeric value for the learning rate. Default is 0.01.}

\item{\code{max_iter}}{An integer specifying the maximum number of iterations for gradient descent. Default is 1000.}

\item{\code{classification_type}}{A character string: "binary" for binary classification or "softmax" for multinomial classification. Default is "binary".}

\item{\code{regularization}}{The type of regularization to apply. Options are "l1", "l2", or \code{NULL} (no regularization). Default is \code{NULL}.}

\item{\code{reg_lambda}}{A numeric value for the strength of the regularization. Default is 0.01.}

\item{\code{tolerance}}{A numeric value for the convergence threshold. Default is 1e-4.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
An instance of the LogisticRegression class.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LogisticRegression-print"></a>}}
\if{latex}{\out{\hypertarget{method-LogisticRegression-print}{}}}
\subsection{Method \code{print()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LogisticRegression$print()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
None. Prints the information to the console.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LogisticRegression-summary"></a>}}
\if{latex}{\out{\hypertarget{method-LogisticRegression-summary}{}}}
\subsection{Method \code{summary()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LogisticRegression$summary(
  class_names = NULL,
  plot_importance = TRUE,
  show_losses = TRUE
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{class_names}}{An optional character vector specifying the names of the classes. If \code{NULL},
default names ("Class 0", "Class 1", etc.) are used.}

\item{\code{plot_importance}}{A logical value indicating whether to display a bar plot of feature importance.
Default is \code{TRUE}.}

\item{\code{show_losses}}{A logical value indicating whether to display the training loss history.
Default is \code{TRUE}.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
None. Prints the summary and optionally plots the feature importance.
Sigmoid Activation Function

This method applies the sigmoid activation function to the input.
The sigmoid function is defined as \eqn{1 / (1 + exp(-z))}.
It maps any real number to a value between 0 and 1.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LogisticRegression-sigmoid"></a>}}
\if{latex}{\out{\hypertarget{method-LogisticRegression-sigmoid}{}}}
\subsection{Method \code{sigmoid()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LogisticRegression$sigmoid(z)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{z}}{A numeric vector or matrix of inputs.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A numeric vector or matrix with the sigmoid function applied to each element.
Softmax Activation Function

This method applies the softmax activation function to the input.
The softmax function is defined as:
\deqn{softmax(z) = exp(z) / sum(exp(z))}
It is used to normalize outputs to a probability distribution across multiple classes.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LogisticRegression-softmax"></a>}}
\if{latex}{\out{\hypertarget{method-LogisticRegression-softmax}{}}}
\subsection{Method \code{softmax()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LogisticRegression$softmax(z)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{z}}{A numeric matrix where each row represents the unnormalized logits for a single sample.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A numeric matrix where each row contains the normalized probabilities for each class.
Forward Pass

This method performs a forward pass through the logistic regression model.
It computes the logits and applies the appropriate activation function
(sigmoid for binary classification, softmax for multinomial classification).
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LogisticRegression-forward"></a>}}
\if{latex}{\out{\hypertarget{method-LogisticRegression-forward}{}}}
\subsection{Method \code{forward()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LogisticRegression$forward(x)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{x}}{A numeric matrix of input features. Each row represents a sample, and each column represents a feature.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A numeric vector (for binary classification) or a numeric matrix (for multinomial classification)
containing the predicted probabilities.
Logarithmic Loss Function

This method computes the log loss (logarithmic loss) for binary classification.
Log loss measures the performance of a classification model whose output is a probability
value between 0 and 1. A lower log loss indicates a better model.

The formula for log loss is:
\deqn{-mean(y_true * log(y_pred) + (1 - y_true) * log(1 - y_pred))}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LogisticRegression-log_loss"></a>}}
\if{latex}{\out{\hypertarget{method-LogisticRegression-log_loss}{}}}
\subsection{Method \code{log_loss()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LogisticRegression$log_loss(y_true, y_pred)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{y_true}}{A numeric vector of true binary labels (0 or 1).}

\item{\code{y_pred}}{A numeric vector of predicted probabilities (values between 0 and 1).}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A numeric value representing the log loss.
Cross-Entropy Loss Function

This method computes the cross-entropy loss for multinomial classification.
Cross-entropy loss measures the performance of a classification model whose output is a probability
distribution across multiple classes.

The formula for cross-entropy loss is:
\deqn{-mean(sum(y_true_one_hot * log(y_pred), axis=1))}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LogisticRegression-cross_entropy_loss"></a>}}
\if{latex}{\out{\hypertarget{method-LogisticRegression-cross_entropy_loss}{}}}
\subsection{Method \code{cross_entropy_loss()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LogisticRegression$cross_entropy_loss(y_true, y_pred)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{y_true}}{A numeric vector of true class labels (integer values starting from 0).}

\item{\code{y_pred}}{A numeric matrix of predicted probabilities where each row represents the
predicted probability distribution for a sample, and each column corresponds to a class.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A numeric value representing the cross-entropy loss.
Update Weights Using Gradient Descent

This method updates the weights of the logistic regression model using gradient descent.
The gradients are computed based on the predicted probabilities and true labels, and
regularization L1 or L2 is applied if specified.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LogisticRegression-update_weights"></a>}}
\if{latex}{\out{\hypertarget{method-LogisticRegression-update_weights}{}}}
\subsection{Method \code{update_weights()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LogisticRegression$update_weights(x, y)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{x}}{A numeric matrix of input features. Each row represents a sample, and each column represents a feature.}

\item{\code{y}}{A numeric vector of true labels. For binary classification, labels should be 0 or 1.
For multinomial classification, labels should be integers starting from 0.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
None. The weights are updated in place.
Initialize Model Weights

This method initializes the weights of the logistic regression model. The weights are
randomly generated from a normal distribution.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LogisticRegression-initialize_weights"></a>}}
\if{latex}{\out{\hypertarget{method-LogisticRegression-initialize_weights}{}}}
\subsection{Method \code{initialize_weights()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LogisticRegression$initialize_weights(input_dim, num_classes = 1, seed = 42)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{input_dim}}{An integer specifying the number of features in the input data.}

\item{\code{num_classes}}{An integer specifying the number of classes. Default is 1 for binary classification.}

\item{\code{seed}}{An integer for setting the random seed to ensure reproducibility. Default is 42.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
None. The weights are initialized in place.
Train the Logistic Regression Model

This method trains the logistic regression model using gradient descent on the provided training data.
It initializes the model weights, computes the loss for each epoch, and updates the weights
iteratively to minimize the loss. The training stops when the loss converges or the maximum
number of iterations is reached.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LogisticRegression-fit"></a>}}
\if{latex}{\out{\hypertarget{method-LogisticRegression-fit}{}}}
\subsection{Method \code{fit()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LogisticRegression$fit(X_train, y_train)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{X_train}}{A numeric matrix of features for the training set. Each row represents a sample,
and each column represents a feature.}

\item{\code{y_train}}{A numeric vector of target labels for the training set. For binary classification,
labels should be 0 or 1. For multinomial classification, labels should be integers starting from 0.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
None. The model is trained in place, and the weights and training losses are updated.
print(model$losses)
Predict Class Labels

This method predicts class labels for the given test set based on the trained logistic regression model.
For binary classification, it thresholds the predicted probabilities at 0.5. For multinomial classification,
it selects the class with the highest predicted probability.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LogisticRegression-predict"></a>}}
\if{latex}{\out{\hypertarget{method-LogisticRegression-predict}{}}}
\subsection{Method \code{predict()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LogisticRegression$predict(X_test)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{X_test}}{A numeric matrix of features for the test set. Each row represents a sample, and each column represents a feature.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A numeric vector of predicted class labels. For binary classification, the labels are 0 or 1.
For multinomial classification, the labels are integers starting from 0.
Print Model Weights

This method prints the weights of the logistic regression model, including the intercept(s)
and coefficients. The weights are displayed in a human-readable format.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LogisticRegression-print_weights"></a>}}
\if{latex}{\out{\hypertarget{method-LogisticRegression-print_weights}{}}}
\subsection{Method \code{print_weights()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LogisticRegression$print_weights()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
None. This method prints the weights to the console.
Predict Class Probabilities

This method predicts the probabilities of class membership for the given test set
based on the trained logistic regression model. For binary classification, it returns
probabilities for the positive class. For multinomial classification, it returns
the full probability distribution across all classes.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LogisticRegression-predict_proba"></a>}}
\if{latex}{\out{\hypertarget{method-LogisticRegression-predict_proba}{}}}
\subsection{Method \code{predict_proba()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LogisticRegression$predict_proba(X_test)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{X_test}}{A numeric matrix of features for the test set. Each row represents a sample,
and each column represents a feature.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A numeric matrix of predicted probabilities. For binary classification, it returns
a column vector where each element is the probability of the positive class.
For multinomial classification, it returns a matrix where each row represents
the probability distribution across all classes for a sample.
Calculate Precision

This method calculates the precision, which is the ratio of correctly predicted positive observations
to the total predicted positive observations.

Precision is defined as:
\deqn{Precision = \frac{True Positives}{True Positives + False Positives}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LogisticRegression-precision"></a>}}
\if{latex}{\out{\hypertarget{method-LogisticRegression-precision}{}}}
\subsection{Method \code{precision()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LogisticRegression$precision(y_true, y_pred)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{y_true}}{A numeric vector of true labels.}

\item{\code{y_pred}}{A numeric vector of predicted labels.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A numeric value representing the precision.
Calculate Recall

This method calculates the recall (or sensitivity), which is the ratio of correctly predicted positive observations
to all actual positive observations.

Recall is defined as:
\deqn{Recall = \frac{True Positives}{True Positives + False Negatives}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LogisticRegression-recall"></a>}}
\if{latex}{\out{\hypertarget{method-LogisticRegression-recall}{}}}
\subsection{Method \code{recall()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LogisticRegression$recall(y_true, y_pred)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{y_true}}{A numeric vector of true labels.}

\item{\code{y_pred}}{A numeric vector of predicted labels.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A numeric value representing the recall.
Calculate F1-Score

This method calculates the F1-score, which is the harmonic mean of precision and recall.
It provides a balance between precision and recall.

F1-score is defined as:
\deqn{F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LogisticRegression-f1_score"></a>}}
\if{latex}{\out{\hypertarget{method-LogisticRegression-f1_score}{}}}
\subsection{Method \code{f1_score()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LogisticRegression$f1_score(y_true, y_pred)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{y_true}}{A numeric vector of true labels.}

\item{\code{y_pred}}{A numeric vector of predicted labels.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A numeric value representing the F1-score.
Generate Confusion Matrix

This method generates a confusion matrix to evaluate the performance of a classification model.
The confusion matrix shows the number of correct and incorrect predictions for each class.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LogisticRegression-confusion_matrix"></a>}}
\if{latex}{\out{\hypertarget{method-LogisticRegression-confusion_matrix}{}}}
\subsection{Method \code{confusion_matrix()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LogisticRegression$confusion_matrix(y_true, y_pred)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{y_true}}{A numeric vector of true labels.}

\item{\code{y_pred}}{A numeric vector of predicted labels.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A matrix where the rows represent the true classes and the columns represent the predicted classes.
Export Model to PMML

This method exports the trained logistic regression model to a PMML (Predictive Model Markup Language) file.
PMML is a standard format for representing predictive models that can be used in various tools and platforms.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LogisticRegression-export_pmml"></a>}}
\if{latex}{\out{\hypertarget{method-LogisticRegression-export_pmml}{}}}
\subsection{Method \code{export_pmml()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LogisticRegression$export_pmml(file_path = "model.pmml")}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{file_path}}{A character string specifying the path where the PMML file should be saved. Default is \code{"model.pmml"}.}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
The method checks if the model has been trained before exporting. It supports both binary and multinomial
logistic regression models. The resulting PMML file contains the coefficients, intercept, and other
necessary metadata to represent the logistic regression model.

For binary classification, the model outputs probabilities for two classes (default categories: \code{"0"} and \code{"1"}).
For multinomial classification, it outputs probabilities for multiple classes.
}

\subsection{Returns}{
None. The method saves the PMML file to the specified path.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LogisticRegression-clone"></a>}}
\if{latex}{\out{\hypertarget{method-LogisticRegression-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{LogisticRegression$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
